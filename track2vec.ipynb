{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deezer playlist dataset et recomandandation de morceaux avec word2vec\n",
    "\n",
    "Dans ce mini projet nous allons mettre au point un réseau word2vec et nous en servir pour construire un outil de complétion de playlist (suggestion de morceaux). Les données sont hébergées sur le dépot suivant : http://github.com/comeetie/deezerplay.git. Pour en savoir plus sur word2vec et les données que nous allons utiliser vous pouvez lire les deux références sivantes :\n",
    "\n",
    "- Efficient estimation of word representations in vector space, Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. (https://arxiv.org/abs/1301.3781)\n",
    "- Word2vec applied to Recommendation: Hyperparameters Matter, H. Caselles-Dupré, F. Lesaint and J. Royo-Letelier. (https://arxiv.org/pdf/1804.04212.pdf)\n",
    "\n",
    "Les éléments que vous devez réaliser sont mis en évidence en <span style=\"color:red\">rouge</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données\n",
    "Les données sont sous la forme d'une liste de playlists. Chaque playlist est elle même une liste avec l'identifiant Deezer du morceau suivi de l'identifiant de l'artiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données de playlist\n",
    "import numpy as np\n",
    "data = np.load(\"./data/music_2.npy\",allow_pickle=True)\n",
    "[len(data), np.mean([len(p) for p in data])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données sur lequel nous allons travailler contient 100 000 playlists qui sont composées d'en moyenne 24.1 morceaux. Nous allons commencer par ne conserver que les identifiants des morceaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separation des ids de morceau et d'artiste\n",
    "playlist_track = [list(filter(lambda w: w.split(\"_\")[0]==u\"track\",playlist)) for playlist in data]\n",
    "playlist_artist = [list(filter(lambda w: w.split(\"_\")[0]==u\"artist\",playlist)) for playlist in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de morceaux != ?\n",
    "tracks = np.unique(np.concatenate(playlist_track))\n",
    "Vt = len(tracks)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_track[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de morceaux différents dans ce data-set est assez élevé avec plus de 300 000 morceaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un dictionnnaire de morceau\n",
    "Nous allons affecter à chaque morceau un entier qui nous servira d'identifiant unique et d'entrée pour notre réseau. Pour économiser un peu nos ressources nous allons travailler dans ce TP que sur les morceaux qui apparaissent dans au moins deux playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre d'occurence de chaque morceau ?\n",
    "track_counts = dict((tracks[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track:\n",
    "    for a in p:\n",
    "        track_counts[a]=track_counts[a]+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage des morceaux peu fréquents pour gagner un peu de temps au vue de nos ressources en temps de calcul\n",
    "playlist_track_filter = [list(filter(lambda a : track_counts[a]> 1, playlist)) for playlist in playlist_track]\n",
    "# récupération des comptages\n",
    "counts  =  np.array(list(track_counts.values()))\n",
    "# trie\n",
    "order = np.argsort(-counts)\n",
    "# création de notre liste d'identifiants deezer\n",
    "tracks_list_ordered = np.array(list(track_counts.keys()))[order]\n",
    "# Taille de notre vocabulaire = nombre de morceaux conservés\n",
    "Vt=np.where(counts[order]==1)[0][0]\n",
    "# construction d'un dict id_morceaux id [0,Vt]\n",
    "track_dict = dict((tracks_list_ordered[i],i) for i in range(0, Vt))\n",
    "# conversion des playlists en liste d'entiers\n",
    "corpus_num_track = [[track_dict[track] for track in play ] for play in playlist_track_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_num_track[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des ensembles d'apprentissage de test et de validation\n",
    "\n",
    "Pour apprendre les paramètres de notre méthode nous allons conserver les $l-1$ premiers morceaux de chaque playlist (avec $l$ la longueur de la playlist) pour l'apprentissage. Pour évaluer les performances de completion de notre méthode nous conservons pour chaque playlist les deux derniers morceaux. L'objectif sera de trouver le dernier à partir de l'avant dernier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble de test et d'apprentissage\n",
    "index_tst = np.random.choice(100000,20000)\n",
    "index_val = np.setdiff1d(range(100000),index_tst)\n",
    "# le debut de chaque playlist est conservé pour l'apprentissage\n",
    "play_app  = [corpus_num_track[i][:(len(corpus_num_track[i])-1)] # On retire le dernier son de chaque playlist (en retirant également les playlists vide et les playlists avec un seul son)\n",
    "             for i in range(len(corpus_num_track)) if len(corpus_num_track[i])>1]\n",
    "# les deux derniers élements pour le test et la validation\n",
    "play_tst  = np.array([corpus_num_track[i][(len(corpus_num_track[i])-2):len(corpus_num_track[i])] \n",
    "             for i in index_tst if len(corpus_num_track[i])>3])\n",
    "play_val  = np.array([corpus_num_track[i][(len(corpus_num_track[i])-2):len(corpus_num_track[i])] \n",
    "             for i in index_val if len(corpus_num_track[i])>3])[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import de Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense,Flatten\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper-paramètres de word2vec :\n",
    "\n",
    "La méthode word2vec fait intervenir un certain nombre d'hyper paramètres. Nous allons les définir et leur donner des premières valeurs que nous affinerons par la suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension de l'espace latent\n",
    "vector_dim = 50\n",
    "# taille de la fenêtre de voisinage\n",
    "window_width = 5\n",
    "# sur-échantillonage des exemples négatifs\n",
    "neg_sample = 17\n",
    "# taille des mini-batchs\n",
    "min_batch_size = 125\n",
    "# coeff pour la loi de tirage des exemples negatifs\n",
    "samp_coef = 0.8\n",
    "# coeff pour le subsampling\n",
    "sub_samp = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des tables de probabilité de tirage (lissée) et non lissée\n",
    "\n",
    "Pour tirer les exemples négatifs nous avons besoin des fréquences lissées de chaque morceau dans notre dataset. De même pour sous échantilloner les morceaux très fréquents nous avons besoin des fréquences brutes. Nous allons calculer ces deux vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des comptages\n",
    "counts = np.array(list(track_counts.values()),dtype='float')[order[:Vt]]\n",
    "# normalisation\n",
    "st =  counts/np.sum(counts)\n",
    "# lissage\n",
    "st_smooth = np.power(st,samp_coef)\n",
    "st_smooth = st_smooth/np.sum(st_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du réseau word2vec\n",
    "\n",
    "Un réseau word2vec prend en entrée deux entiers correspondant à deux morceaux, ceux-ci sont plongés dans un espace latent de dimension (vector_dim) grâce à une couche de type embedding (vous devrez utilisez la même couche pour projeter les deux morceaux). Une fois ces deux vecteurs extraits le réseau doit calculer leur produit scalaire normalisé applelé cosine distance :\n",
    "\n",
    "$$cos(\\theta_{ij})=\\frac{z_i.z_j}{||z_i||||z_j||}$$ \n",
    "\n",
    "Pour réaliser ce traitement vous utiliserez une couche \"Dot\" pour \"dot product\". Le modèle utilise ensuite une couche de type sigmoid pour produire la sortie. Cette sortie vaudra 0 lorsque les deux morceaux sont des morceaux tirés aléatoirement dans l'ensemble du jeu de données et 1 lorsqu'il auront été extraits de la même playlist. <span style=\"color:red\">A vous de créer le modèle keras Track2Vec correspondant à cette architecture.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrée deux entier (couple de morceaux)\n",
    "input_target = Input((1,), dtype='int32')\n",
    "input_context = Input((1,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(Vt, vector_dim)\n",
    "z1 = embedding_layer(input_target)\n",
    "z2 = embedding_layer(input_context)\n",
    "\n",
    "dot_layer = (Dot(axes = 2, normalize = True)([z1, z2]))\n",
    "flatten_layer = Flatten()(dot_layer) # Réduction à une dimension\n",
    "\n",
    "output = Dense(1, activation='sigmoid',name=\"classif\")(flatten_layer)\n",
    "\n",
    "# définition du modèle\n",
    "Track2Vec = Model(inputs=[input_target, input_context], outputs=output)\n",
    "Track2Vec.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Track2Vec.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du générateur de données\n",
    "\n",
    "Pour apprendre la couche de projection au coeur de notre modèle nous allons construire un générateur d'exemples positifs et négatifs de paires de morceaux proches ou aléatoires issus de nos données d'entrainement. La fonction suivante va permettre de générer de tels exemples à partir d'une playlist (seq) fournie en entrée. Cette fonction va tout d'abord construire tous les couples de morceaux pouvant être extrait de la séquence s'ils se situent à moins de (windows) distance l'un de l'autre. Ces paires constitueront les paires positives. Les paires concernant deux morceaux très fréquents seront supprimés avec une probabilité qui dépendra de leur fréquence. Enfin un nombre d'exemples négatifs (correpondant à neg_samples * nombre d'exemple positif) vont être tirés aléatoirement en utilisant la table de tirage (neg_sampling_table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction générant les données associées a une séquence\n",
    "# seq : séquence d'entrée\n",
    "# neg_samples : nombre d'exemples négatifs générés par exemple positif\n",
    "# neg_sampling_table : probabilité de tirage des exemples négatifs\n",
    "# sub sampling_table : probabilité servant a sous échantilloner\n",
    "# sub_t : paramètre de sous échantillonage\n",
    "def word2vecSampling(seq,window,neg_samples,neg_sampling_table,sub_sampling_table,sub_t):\n",
    "    # taille du vocabulaire\n",
    "    V = len(neg_sampling_table)\n",
    "    # création des paires positives à partir de la séquence\n",
    "    positives = skipgrams(sequence=seq, vocabulary_size=V, window_size=window,negative_samples=0)\n",
    "    ppairs    = np.array(positives[0])\n",
    "    # sous échantillonage\n",
    "    if (ppairs.shape[0]>0):\n",
    "        f = sub_sampling_table[ppairs[:,0]]\n",
    "        subprob = ((f-sub_t)/f)-np.sqrt(sub_t/f)\n",
    "        tokeep = (subprob<np.random.uniform(size=subprob.shape[0])) | (subprob<0)\n",
    "        ppairs = ppairs[tokeep,:]\n",
    "    nbneg     = ppairs.shape[0]*neg_samples\n",
    "    # tirage des paires négatives\n",
    "    if (nbneg > 0):\n",
    "        negex     = np.random.choice(V, nbneg, p=neg_sampling_table)\n",
    "        negexcontext = np.repeat(ppairs[:,0],neg_samples)\n",
    "        npairs    = np.transpose(np.stack([negexcontext,negex]))\n",
    "        pairs     = np.concatenate([ppairs,npairs],axis=0)\n",
    "        labels    = np.concatenate([np.repeat(1,ppairs.shape[0]),np.repeat(0,nbneg)])\n",
    "        perm      = np.random.permutation(len(labels))\n",
    "        res = [pairs[perm,:],labels[perm]]\n",
    "    else:\n",
    "        res=[[],[]]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Utilisez cette fonction pour constuire un générateur \"track_ns_generator\" de données qui va générer des exemples positifs et négatifs à partir de \"nbm\" playlists tirées aléatoirement dans le jeu de données \"corpus_num\" fourni en entrée. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition du générateur de couples de morceaux (y=0 <-> aléatoire, y=1 <-> proche dans une playlist)\n",
    "import random\n",
    "def track_ns_generator(corpus_num, nbm):\n",
    "    while 1:\n",
    "        # Tirage de `nbm` playlists aléatoires dans `corpus_num`\n",
    "        playlists = random.sample(corpus_num, nbm)\n",
    "        # Création des paires et de leur label\n",
    "        x1 = []\n",
    "        x2 = []\n",
    "        y = []\n",
    "        for playlist in playlists:\n",
    "            pairs, labels = word2vecSampling(playlist, window_width, neg_sample, st_smooth, st, sub_samp)\n",
    "            x1.extend(list(map(lambda pair: pair[0], pairs))) # Liste des avant-derniers éléments\n",
    "            x2.extend(list(map(lambda pair: pair[1], pairs))) # Liste des derniers éléments\n",
    "            y.extend(labels) # Liste des labels (0 = paire aléatoire; 1 = paire positive)\n",
    "\n",
    "        # Conversion en Array numpy pour la fonction d'entrainement\n",
    "        x1 = np.array(x1).reshape(len(x1))\n",
    "        x2 = np.array(x2).reshape(len(x2))\n",
    "        y = np.array(y).reshape(len(y))\n",
    "\n",
    "        yield [x1, x2], y"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apprentissage\n",
    "Vous devriez maintenant être en mesure d'apprendre votre premier modèle avec le code suivant. Cela devrait durer entre 15 et 30 min."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist=Track2Vec.fit(track_ns_generator(play_app,min_batch_size),steps_per_epoch = 200,epochs=60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sauvegarde de l'espace latent\n",
    "Nous pouvons une fois l'apprentissage effectué sauvegarder la position des morceaux dans l'espace latent avec le code suivant:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des positions des morceaux dans l'espace de projection\n",
    "vectors_tracks = Track2Vec.get_weights()[0]\n",
    "with open('./data/latent_positions.npy', 'wb') as f:\n",
    "    np.save(f, vectors_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et nous pouvons la recharger avec le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_tracks=np.load(\"./data/latent_positions.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation en complétion et évaluation\n",
    "Nous pouvons maintenant nous servir de cet espace pour faire des suggestions. <span style=\"color:red\">Construisez une fonction predict_batch qui prend en entrée un vecteur de numéro de morceaux (seeds), (s) un nombre de proposition à faire, les vecteurs des morceaux dans l'espace latent X et un kd-tree permettant d'accélérer les calculs des plus proches voisins. Pour faire ces propositions cette fonction retournera les indices des s plus proches voisins de chaque seed. </span> Pour que ces predictions ne prennent pas trop de temps vous vous servirez d'un kd-tree (disponnible dans scikit learn) pour accélérer la recherche des plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "kdt = KDTree(vectors_tracks, leaf_size=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(seeds,k,X,kdt):\n",
    "    nearest_neighbors = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        dist, ind = kdt.query([X[seed]], k)\n",
    "        nearest_neighbors.append(ind)\n",
    "\n",
    "    return nearest_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Utilisez cette fonction pour proposer des morceaux pour compléter les playlists du jeu de données de validation (les seeds correspondent à la première colone de play_val).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = predict_batch(play_tst[:,0],10,vectors_tracks,kdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Comparez ces suggestions avec la seconde colonne de play_val (les morceaux effectivement présents). Pour cela vous calculerez le hit@10 qui vaut 1 si le morceau effectivement présent dans la playlist fait partie des 10 propositions (ce score étant moyenné sur l'ensemble de validation) et le NDCG@10 (Normalized Discounted Cumulative Gain) qui prend en compte l'ordre des propositions. Ce second score vaut $1/log2(k+1)$ si la proposition k (k entre 1 et 10) est la proposition correcte et 0 si aucne proposition n'est correcte. Comme précedement vous calulerez le score moyen sur l'ensemble de validation. </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndgcAtK(tracks_set, predictions_set):\n",
    "    hits = map(lambda track, predictions:\n",
    "               (1 / np.log2(np.where(predictions == track)[1][0] + 2)) if track in predictions else 0,\n",
    "               tracks_set, predictions_set)\n",
    "\n",
    "    return np.mean(list(hits))\n",
    "\n",
    "ndgcAtK(play_tst[:,1], indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hitAtK(tracks_set, predictions_set):\n",
    "    hits = map(lambda track, predictions:\n",
    "               1 if track in predictions else 0,\n",
    "               tracks_set, predictions_set)\n",
    "\n",
    "    return np.mean(list(hits))\n",
    "\n",
    "hitAtK(play_tst[:,1], indexes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning des hyper paramètres\n",
    "\n",
    "<span style=\"color:red\">Vous pouvez maintenant essayer de faire varier les hyper paramètres pour améliorer vos performances. Attention au temps de calcul préparez une grille avec une dizaine de configurations différentes et évaluez chacune d'entre elles sur votre ensemble de validation.\n",
    "Evaluez les performances finales de la meilleure configuration trouvée sur l'ensemble de test. N'oubliez pas de sauvergader vos résultats.</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus, un peu de musique\n",
    "\n",
    "Le fichier TrackArtists contient des méta.données sur les morceaux et les artiste pour un sous ensemble des 300000 morceaux présents dans le dataset. Nous pouvons nous en servir pour rechercher le numéro d'un morceau à partir de son titre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tr_meta=pd.read_csv(\"./data/TracksArtists.csv\")\n",
    "joindf = pd.DataFrame({\"track_id\":tracks_list_ordered[:Vt],\"index\":range(Vt)})\n",
    "meta = tr_meta.merge(joindf, left_on=\"track_id\",right_on=\"track_id\")\n",
    "meta.set_index(\"index\",inplace=True)\n",
    "meta[[\"title\",\"name\",\"preview\",\"track_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_track(title):\n",
    "    return meta.loc[meta[\"title\"]==title,:].index[0]\n",
    "\n",
    "tr=find_track(\"Hexagone\")\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radio\n",
    "\n",
    "L'api de deeezer permet de récupérer des informations sur les morceaux du dataset à partir de leur id deezer. Parmi ces infos lorsqu'elle est disponnible une url d'écoute d'un extrait gratuit est fournie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "def gettrackinfo(number):\n",
    "    track_url =  \"https://api.deezer.com/track/{}\".format(tracks_list_ordered[number].split(\"_\")[1])\n",
    "    with urllib.request.urlopen(track_url) as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "    return data\n",
    "track_apidata = gettrackinfo(find_track(\"Hexagone\"))\n",
    "track_apidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons donc nous en servir pour écouter un extrait :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio, clear_output\n",
    "display(Audio(track_apidata[\"preview\"],autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Créez une fonction radio qui prend en entrée un numéro de morceau dans le dataset et lance une série de nb_track morceaux en tirant aléatoirement dans le voisinage du morceau courant le morceau suivant à écouter. La taille du voisinage sera paramétrable et vous supprimerez des propositions les morceaux déjà écoutés. Vous traiterez les exceptions si le morceau ne dispose pas d'extrait disponnible. Vous pouvez supprimer le morceau courant avec la fonction clear_display.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def start_radio(seed,nb_candidates,duration,nbsteps=20):\n",
    "    print(meta.loc[seed,\"title\"])\n",
    "    display(Audio(meta.loc[seed,\"preview\"],autoplay=True))\n",
    "    time.sleep(duration)\n",
    "    clear_output()\n",
    "    already_played = [seed]\n",
    "    for i in range(nbsteps):\n",
    "        try:\n",
    "            # Détermination du prochain morceau à lire\n",
    "            while True:\n",
    "                seed = random.choice(predict_batch([seed],nb_candidates,vectors_tracks,kdt)[0][0])\n",
    "                if not seed in already_played:\n",
    "                    break\n",
    "\n",
    "            track_apidata = gettrackinfo(seed)\n",
    "            print(track_apidata[\"title\"])\n",
    "            display(Audio(track_apidata[\"preview\"],autoplay=True))\n",
    "            time.sleep(duration)\n",
    "            clear_output()\n",
    "            already_played.append(seed)\n",
    "        except:\n",
    "            print(\"track not found\")\n",
    "            pass\n",
    "        clear_output()\n",
    "\n",
    "start_radio(find_track(\"Sapés comme jamais (Pilule bleue)\"),5,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_radio(find_track(\"Sapés comme jamais (Pilule bleue)\"),5,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}